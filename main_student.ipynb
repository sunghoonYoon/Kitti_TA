{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/sunghoonYoon/Kitti_TA\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "####NOTE: you should change the \"runtime option to use GPU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kitti_options = NONE #SS: Semantic Segmentation , SM: Stereo Matching, OF: Optical flow /// Only these three options are available\n",
    "\n",
    "assert Kitti_options in ['SS','SM','OF']\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "from imageio import imread, imwrite\n",
    "\n",
    "########\n",
    "from Kitti_TA.kitti_seg import decode_segmap, denorm, YOUR_IMPLEMENTATION ##import segmentation network (deeplabWplus)\n",
    "from Kitti_TA.kitti_stereo import YOUR_IMPLEMENTATION #import stereo matching network\n",
    "from Kitti_TA.kitti_flow import ArrayToTensor, flow2rgb, FlowNetS\n",
    "\n",
    "\n",
    "left_image_path = '/content/drive/MyDrive/TA_stereo/KITTI_2015/testing/left.png'\n",
    "right_image_path = '/content/drive/MyDrive/TA_stereo/KITTI_2015/testing/right.png'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "net_SS = YOUR_IMPLEMENTATION.cuda() # declare Network and the number of class=19\n",
    "state_dict= torch.load('/content/drive/MyDrive/TA_segmentation/cityscapes_best.pth')\n",
    "net_SS = torch.nn.DataParallel(net_SS)\n",
    "    \n",
    "net_SS.YOUR_IMPLEMENTATION(state_dict['state_dict'],strict=False) #load the checkpoint(state_dict) \n",
    "\n",
    "net_SS.eval()\n",
    "\n",
    "image= np.asarray(Image.open(left_image_path)).convert('RGB')\n",
    "\n",
    "MEAN = [0.45734706, 0.43338275, 0.40058118]\n",
    "STD = [0.23965294, 0.23532275, 0.2398498]\n",
    "\n",
    "toTensor = transforms.ToTensor()\n",
    "normTensor = transforms.Normalize(MEAN,STD)\n",
    "imageT = normTensor(toTensor(image))\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    imageT = F.interpolate(imageT.unsqueeze(0), size=(512,1024),mode='bilinear',align_corners=True)\n",
    "    YOUR_IMPLEMENTATION # get segmentation results using network\n",
    "\n",
    "    YOUR_IMPLEMENTATION # Take softmax to the network output in channel dimension\n",
    "    YOUR_IMPLEMENTATION # Get max indices from the softmax-ed result (use argmax function)\n",
    "\n",
    "segmap = YOUR_IMPLEMENTATION #use the function that we provide (convert prediction into RBG color map)\n",
    "\n",
    "###Visualization###\n",
    "'''\n",
    "YOUR IMPLEMENTATION\n",
    "#Visualize the segmentation result and image together with transparency (alpha=0.7) mode. use plt function\n",
    "\n",
    "''' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stereo matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_disp = 192\n",
    "net_SM = YOUR_IMPLEMENTATION # declare Network and the max disparity is 192\n",
    "net_SM = net_SM.cuda()\n",
    "net_SM.eval()\n",
    "\n",
    "checkpoint = torch.load('/content/drive/MyDrive/TA_stereo/pretrained_model_KITTI2015.tar')\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in checkpoint['state_dict'].items():\n",
    "    name = k[7:]\n",
    "    new_state_dict[name] = v    \n",
    "net_SM.load_state_dict(new_state_dict)    \n",
    "normal_mean_var = {'mean': [0.485, 0.456, 0.406],\n",
    "                    'std': [0.229, 0.224, 0.225]}\n",
    "infer_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                        transforms.Normalize(**normal_mean_var)])    \n",
    "\n",
    "\n",
    "imgL_o = Image.open(left_image_path).convert('RGB')\n",
    "imgR_o = Image.open(right_image_path).convert('RGB')\n",
    "\n",
    "imgL = infer_transform(imgL_o)\n",
    "imgR = infer_transform(imgR_o) \n",
    "\n",
    "# pad to width and hight to 16 times\n",
    "if imgL.shape[1] % 16 != 0:\n",
    "    times = imgL.shape[1]//16       \n",
    "    top_pad = (times+1)*16 -imgL.shape[1]\n",
    "else:\n",
    "    top_pad = 0\n",
    "\n",
    "if imgL.shape[2] % 16 != 0:\n",
    "    times = imgL.shape[2]//16                       \n",
    "    right_pad = (times+1)*16-imgL.shape[2]\n",
    "else:\n",
    "    right_pad = 0    \n",
    "\n",
    "imgL = F.pad(imgL,(0,right_pad, top_pad,0)).unsqueeze(0)\n",
    "imgR = F.pad(imgR,(0,right_pad, top_pad,0)).unsqueeze(0)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "net_SM.eval()\n",
    "\n",
    "imgL = imgL.cuda()\n",
    "imgR = imgR.cuda()  \n",
    "        \n",
    "\n",
    "with torch.no_grad():\n",
    "    disp = YOUR_IMPLEMENTATION # get output from the network\n",
    "\n",
    "    disp = torch.squeeze(disp)\n",
    "    pred_disp = disp.data.cpu().numpy()\n",
    "\n",
    "\n",
    "if top_pad !=0 or right_pad != 0:\n",
    "    img = pred_disp[top_pad:,:-right_pad]\n",
    "else:\n",
    "    img = pred_disp\n",
    "\n",
    "####Visualize####\n",
    "'''\n",
    "YOUR IMPLEMENTATION\n",
    "#Visualize the left image and left disparity using plt function.\n",
    "\n",
    "'''\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optical flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('/content/drive/MyDrive/TA_opticalflow/flownets_bn_EPE2.459.pth.tar')\n",
    "\n",
    "net_OF = FlowNetS() # declare Network\n",
    "net_OF = net_OF.cuda()\n",
    "net_OF.eval()\n",
    "\n",
    "input_transform = transforms.Compose([\n",
    "    ArrayToTensor(),\n",
    "    transforms.Normalize(mean=[0,0,0], std=[255,255,255]),\n",
    "    transforms.Normalize(mean=[0.411,0.432,0.45], std=[1,1,1])\n",
    "])\n",
    "\n",
    "\n",
    "img1= input_transform(imread('/content/drive/MyDrive/TA_stereo/2011_09_26_drive_0096_sync/image_02/data/0000000000.png'))\n",
    "img2= input_transform(imread('/content/drive/MyDrive/TA_stereo/2011_09_26_drive_0096_sync/image_02/data/0000000001.png'))\n",
    "\n",
    "input_var = torch.cat([img1, img2]).unsqueeze(0)\n",
    "\n",
    "net_OF.load_state_dict(state_dict['state_dict'])\n",
    "\n",
    "bidirectional = True\n",
    "if bidirectional:\n",
    "    # feed inverted pair along with normal pair\n",
    "    inverted_input_var = torch.cat([img2, img1]).unsqueeze(0)\n",
    "    input_var = torch.cat([input_var, inverted_input_var])\n",
    "\n",
    "input_var = input_var.cuda()\n",
    "# compute output\n",
    "flow_output = net_OF(input_var)\n",
    "\n",
    "rgb_flow = flow2rgb(20 * flow_output[0], max_value=20)\n",
    "rgb_inv_flow = flow2rgb(20 * flow_output[1], max_value=20)\n",
    "to_save = (rgb_flow * 255).astype(np.uint8).transpose(1,2,0)\n",
    "to_save_inv = (rgb_inv_flow * 255).astype(np.uint8).transpose(1,2,0)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('flow result')\n",
    "plt.imshow(to_save)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title('inv flow result')\n",
    "plt.imshow(to_save_inv)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = '/content/drive/MyDrive/TA_stereo/2011_09_26_drive_0096_sync/image_02/data/*.png'\n",
    "save_dir = '/content/drive/MyDrive/TA_segmentation/output'\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "files = glob.glob(file_dir)\n",
    "\n",
    "for file in files:\n",
    "  with torch.no_grad():\n",
    "    image = np.asarray(Image.open(file).convert('RGB'))\n",
    "    imageT = normTensor(toTensor(image))\n",
    "    imageT = F.interpolate(imageT.unsqueeze(0), size=(512,1024),mode='bilinear',align_corners=True)\n",
    "    out = net(imageT.cuda())\n",
    "\n",
    "    prob = F.softmax(out,1)\n",
    "    pred = np.argmax(prob[0].detach().cpu().numpy(),axis=0)\n",
    "\n",
    "    segmap = decode_segmap(pred)\n",
    "\n",
    "    plt.imshow(denorm(imageT)[0].permute(1,2,0))\n",
    "    plt.imshow(segmap,alpha=0.7)\n",
    "    # plt.show()\n",
    "    plt.savefig(os.path.join(save_dir,os.path.basename(file)))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "print(save_dir+'segmentation_video.avi')\n",
    "out = cv2.VideoWriter(save_dir+\"/\"+'segmentation_video.avi',cv2.VideoWriter_fourcc(*\"MJPG\"), 2, (1024,512))\n",
    "\n",
    "for i in range(2):\n",
    "    img = cv2.imread(os.path.join('/content/drive/MyDrive/TA_segmentation/output',\"%010d.png\"%i))\n",
    "    print(img.shape)\n",
    "    out.write(img)\n",
    "\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
