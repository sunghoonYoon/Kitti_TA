{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/sunghoonYoon/Kitti_TA\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kitti_options = NONE #SS: Semantic Segmentation , SM: Stereo Matching, OF: Optical flow /// Only these three options are available\n",
    "\n",
    "assert Kitti_options in ['SS','SM','OF']\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "\n",
    "########\n",
    "from Kitti_TA.kitti_seg import decode_segmap, denorm, YOUR_IMPLEMENTATION ##import segmentation network (deeplabWplus)\n",
    "from Kitti_TA.kitti_stereo import YOUR_IMPLEMENTATION #import stereo matching network\n",
    "\n",
    "\n",
    "left_image_path = '/content/drive/MyDrive/TA_stereo/KITTI_2015/testing/left.png'\n",
    "right_image_path = '/content/drive/MyDrive/TA_stereo/KITTI_2015/testing/right.png'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Kitti_options == 'SS':\n",
    "    net_SS = YOUR_IMPLEMENTATION.cuda() # declare Network and the number of class=19\n",
    "    state_dict= torch.load('/content/drive/MyDrive/TA_segmentation/cityscapes_best.pth')\n",
    "    net_SS = torch.nn.DataParallel(net_SS)\n",
    "     \n",
    "    net_SS.YOUR_IMPLEMENTATION(state_dict['state_dict'],strict=False) #load the checkpoint(state_dict) \n",
    "\n",
    "    net_SS.eval()\n",
    "\n",
    "    image= np.asarray(Image.open(left_image_path)).convert('RGB')\n",
    "    \n",
    "    MEAN = [0.45734706, 0.43338275, 0.40058118]\n",
    "    STD = [0.23965294, 0.23532275, 0.2398498]\n",
    "\n",
    "    toTensor = transforms.ToTensor()\n",
    "    normTensor = transforms.Normalize(MEAN,STD)\n",
    "    imageT = normTensor(toTensor(image))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        imageT = F.interpolate(imageT.unsqueeze(0), size=(512,1024),mode='bilinear',align_corners=True)\n",
    "        YOUR_IMPLEMENTATION # get segmentation results using network\n",
    "\n",
    "        YOUR_IMPLEMENTATION # Take softmax to the network output in channel dimension\n",
    "        YOUR_IMPLEMENTATION # Get max indices from the softmax-ed result (use argmax function)\n",
    "    \n",
    "    segmap = YOUR_IMPLEMENTATION #use the function that we provide (convert prediction into RBG color map)\n",
    "\n",
    "    ###Visualization###\n",
    "    '''\n",
    "    YOUR IMPLEMENTATION\n",
    "    #Visualize the segmentation result and image together with transparency (alpha=0.7) mode. use plt function\n",
    "\n",
    "    ''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stereo matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Kitti_options == 'SM':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    max_disp = 192\n",
    "    net_SM = YOUR_IMPLEMENTATION # declare Network and the max disparity is 192\n",
    "    net_SM = net_SM.cuda()\n",
    "    net_SM.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    checkpoint = torch.load('/content/drive/MyDrive/TA_stereo/pretrained_model_KITTI2015.tar')\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in checkpoint['state_dict'].items():\n",
    "        name = k[7:]\n",
    "        new_state_dict[name] = v    \n",
    "    net_SM.load_state_dict(new_state_dict)    \n",
    "    normal_mean_var = {'mean': [0.485, 0.456, 0.406],\n",
    "                        'std': [0.229, 0.224, 0.225]}\n",
    "    infer_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                            transforms.Normalize(**normal_mean_var)])    \n",
    "\n",
    "\n",
    "    imgL_o = Image.open(left_image_path).convert('RGB')\n",
    "    imgR_o = Image.open(right_image_path).convert('RGB')\n",
    "\n",
    "    imgL = infer_transform(imgL_o)\n",
    "    imgR = infer_transform(imgR_o) \n",
    "\n",
    "    # pad to width and hight to 16 times\n",
    "    if imgL.shape[1] % 16 != 0:\n",
    "        times = imgL.shape[1]//16       \n",
    "        top_pad = (times+1)*16 -imgL.shape[1]\n",
    "    else:\n",
    "        top_pad = 0\n",
    "\n",
    "    if imgL.shape[2] % 16 != 0:\n",
    "        times = imgL.shape[2]//16                       \n",
    "        right_pad = (times+1)*16-imgL.shape[2]\n",
    "    else:\n",
    "        right_pad = 0    \n",
    "\n",
    "    imgL = F.pad(imgL,(0,right_pad, top_pad,0)).unsqueeze(0)\n",
    "    imgR = F.pad(imgR,(0,right_pad, top_pad,0)).unsqueeze(0)\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    net_SM.eval()\n",
    "\n",
    "    imgL = imgL.cuda()\n",
    "    imgR = imgR.cuda()  \n",
    "           \n",
    "\n",
    "    with torch.no_grad():\n",
    "        disp = YOUR_IMPLEMENTATION # get output from the network\n",
    "\n",
    "        disp = torch.squeeze(disp)\n",
    "        pred_disp = disp.data.cpu().numpy()\n",
    "\n",
    "\n",
    "    if top_pad !=0 or right_pad != 0:\n",
    "        img = pred_disp[top_pad:,:-right_pad]\n",
    "    else:\n",
    "        img = pred_disp\n",
    "\n",
    "    ####Visualize####\n",
    "    '''\n",
    "    YOUR IMPLEMENTATION\n",
    "    #Visualize the left image and left disparity using plt function.\n",
    "\n",
    "    '''\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
