{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/sunghoonYoon/Kitti_TA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from kitti_seg import DeepWV3Plus, decode_segmap, denorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = DeepWV3Plus(num_classes=19).cuda()\n",
    "state_dict= torch.load('/content/drive/MyDrive/ME459_segmentation/cityscapes_best.pth')\n",
    "net = torch.nn.DataParallel(net)\n",
    "\n",
    "# print(state_dict)\n",
    "net.load_state_dict(state_dict['state_dict'],strict=False)\n",
    "\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image= np.asarray(Image.open('/content/drive/MyDrive/ME459_segmentation/kaist_road.jpg').convert('RGB'))\n",
    "MEAN = [0.45734706, 0.43338275, 0.40058118]\n",
    "STD = [0.23965294, 0.23532275, 0.2398498]\n",
    "\n",
    "toTensor = transforms.ToTensor()\n",
    "normTensor = transforms.Normalize(MEAN,STD)\n",
    "imageT = normTensor(toTensor(image))\n",
    "\n",
    "with torch.no_grad():\n",
    "  for i in [1]:\n",
    "    imageT = F.interpolate(imageT.unsqueeze(0), size=(512,1024),mode='bilinear',align_corners=True)\n",
    "    out = net(imageT.cuda())\n",
    "\n",
    "\n",
    "prob = F.softmax(out,1)\n",
    "pred = np.argmax(prob[0].detach().cpu().numpy(),axis=0)\n",
    "\n",
    "segmap = decode_segmap(pred)\n",
    "\n",
    "plt.imshow(denorm(imageT)[0].permute(1,2,0))\n",
    "plt.imshow(segmap,alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stereo matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kitti_stereo import PSMNet, test_img\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_disp = 192\n",
    "model = PSMNet(max_disp)\n",
    "model = model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('/content/drive/MyDrive/ME459_stereo/pretrained_model_KITTI2015.tar')\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in checkpoint['state_dict'].items():\n",
    "    name = k[7:]\n",
    "    new_state_dict[name] = v    \n",
    "model.load_state_dict(new_state_dict)    \n",
    "normal_mean_var = {'mean': [0.485, 0.456, 0.406],\n",
    "                    'std': [0.229, 0.224, 0.225]}\n",
    "infer_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                        transforms.Normalize(**normal_mean_var)])    \n",
    "\n",
    "imgL_o = Image.open(left_image_path).convert('RGB')\n",
    "imgR_o = Image.open(right_image_path).convert('RGB')\n",
    "\n",
    "imgL = infer_transform(imgL_o)\n",
    "imgR = infer_transform(imgR_o) \n",
    "\n",
    "# pad to width and hight to 16 times\n",
    "if imgL.shape[1] % 16 != 0:\n",
    "    times = imgL.shape[1]//16       \n",
    "    top_pad = (times+1)*16 -imgL.shape[1]\n",
    "else:\n",
    "    top_pad = 0\n",
    "\n",
    "if imgL.shape[2] % 16 != 0:\n",
    "    times = imgL.shape[2]//16                       \n",
    "    right_pad = (times+1)*16-imgL.shape[2]\n",
    "else:\n",
    "    right_pad = 0    \n",
    "\n",
    "imgL = F.pad(imgL,(0,right_pad, top_pad,0)).unsqueeze(0)\n",
    "imgR = F.pad(imgR,(0,right_pad, top_pad,0)).unsqueeze(0)\n",
    "\n",
    "start_time = time.time()\n",
    "pred_disp = test_img(imgL,imgR)\n",
    "if top_pad !=0 or right_pad != 0:\n",
    "    img = pred_disp[top_pad:,:-right_pad]\n",
    "else:\n",
    "    img = pred_disp\n",
    "plt.figure()\n",
    "plt.title('left image')\n",
    "plt.imshow(imgL_o)\n",
    "plt.figure()\n",
    "plt.title('disparity output')\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "print('time = %.2f' %(time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
